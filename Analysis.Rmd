---
title: "Project Machine Learning Prediction"
author: "Jorge Espina"
date: "7/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Human Activity Recognition
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Six participants performed 10 bicep curls in five different fashions: exactly according to the correct specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).



## 2. Data Processing

The data is provided with aggregated statistical metrics in each observation window. Columns containing these aggregated values are assigned NA while data is collected. I chose to separate the aggregated data and the raw data into 2 data frames and build models from both. The next section of the code includes creating a training / test partition and separating the aggregated data columns from the raw data, and finally removing the NA values from the summary data.

```{r, eval=FALSE,echo=TRUE}
#seed for reproducibility
set.seed(22)

#Download the data
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "training.csv")

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "testing.csv")

#Full data 
data <- read.csv("training.csv")

#20 Cases for Validation
validation <- read.csv("testing.csv")

class(data$classe)
```
```{r, eval=FALSE,echo=TRUE}
## [1] "factor"

```
```{r, eval=FALSE,echo=TRUE}
levels(data$classe)

```
```{r, eval=FALSE,echo=TRUE}
## [1] "A" "B" "C" "D" "E"
```
```{r, eval=FALSE,echo=TRUE}
dim(data)

```
```{r, eval=FALSE,echo=TRUE}
## [1] 19622   160

```
```{r, eval=FALSE,echo=TRUE}
#Identifying NA level
NA_levels <- unique(apply(data, 2,function(x){sum(is.na(x))}))
number_NA <- dim(data)[1]-NA_levels[2]
non_NA <- number_NA/dim(data)[1]
sprintf("%1.2f%%", 100*non_NA)
```
```{r, eval=FALSE,echo=TRUE}
## [1] "2.07%"
```
```{r, eval=FALSE,echo=TRUE}
#Setting empty spaces and div0 to be NA
data[data == ""] <- NA
data[data=="#DIV/0!"] <- NA
data[data=="<NA>"] <- NA

#Splitting the data for test
set.seed(22)
traindex <- createDataPartition(data$classe,p = 0.8,list = FALSE)
train <- data[traindex,]
test <- data[-traindex,]

#Selecting non-aggregated RAW sensor data
train_raw <- train[which(train$new_window == "no"),]

#Raw sensor data without NA columns(summary data)
train_raw <- train[!colSums(is.na(train)) > 0]

#Testing NA purity
sum(is.na(train_raw))

```
```{r, eval=FALSE,echo=TRUE}
## [1] 0

```
```{r, eval=FALSE,echo=TRUE}
train_sum <- train[which(train$new_window == "yes"),]
test_sum <- test[which(test$new_window == "yes"),]

#Removing full NA columns
train_sum_clean <- subset(train_sum,
                          select=-c(kurtosis_picth_belt,kurtosis_yaw_belt,kurtosis_picth_arm,kurtosis_yaw_arm,skewness_pitch_arm,kurtosis_yaw_dumbbell,skewness_yaw_dumbbell,skewness_yaw_forearm,kurtosis_yaw_forearm,skewness_yaw_belt,skewness_roll_belt.1))

test_sum_clean <- subset(test_sum,
                          select=-c(kurtosis_picth_belt,kurtosis_yaw_belt,kurtosis_picth_arm,kurtosis_yaw_arm,skewness_pitch_arm,kurtosis_yaw_dumbbell,skewness_yaw_dumbbell,skewness_yaw_forearm,kurtosis_yaw_forearm,skewness_yaw_belt,skewness_roll_belt.1))

#Removing NA rows
train_done <- train_sum_clean[complete.cases(train_sum_clean),]
sum(is.na(train_done))

```


```{r, eval=FALSE,echo=TRUE}
## [1] 0
```

## 3. Models
## 3.1 Model No.1
Due to the characteristics of noise in the sensor data, a random forest model is best for this task.
The model achieves an estimated out-of-sample error rate of 0.43%.
The model uses bootstrap resampling with the training set partition provided above to cross-validate against the test set. k-fold cross-validation would be computationally intensive.
  
```{r, eval=FALSE,echo=TRUE}
#Important to not include the X row in the dataset because it is an index and the data is organized alphabetically by class outcome.
model1 <- randomForest(classe ~. , data=train_raw[,-c(1:7)], method="class")
pred_test1 <- predict(model1, test)
pred_train1 <- predict(model1, train)

confusionMatrix(pred_test1, test$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1115    4    0    0    0
##          B    1  755    3    0    0
##          C    0    0  681    2    0
##          D    0    0    0  640    3
##          E    0    0    0    1  718
## 
## Overall Statistics
##                                         
##                Accuracy : 0.9964        
##                  95% CI : (0.994, 0.998)
##     No Information Rate : 0.2845        
##     P-Value [Acc > NIR] : < 2.2e-16     
##                                         
##                   Kappa : 0.9955        
##  Mcnemar's Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9991   0.9947   0.9956   0.9953   0.9958
## Specificity            0.9986   0.9987   0.9994   0.9991   0.9997
## Pos Pred Value         0.9964   0.9947   0.9971   0.9953   0.9986
## Neg Pred Value         0.9996   0.9987   0.9991   0.9991   0.9991
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2842   0.1925   0.1736   0.1631   0.1830
## Detection Prevalence   0.2852   0.1935   0.1741   0.1639   0.1833
## Balanced Accuracy      0.9988   0.9967   0.9975   0.9972   0.9978
```
```{r, eval=FALSE,echo=TRUE}
confusionMatrix(pred_train1, train$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 4464    0    0    0    0
##          B    0 3038    0    0    0
##          C    0    0 2738    0    0
##          D    0    0    0 2573    0
##          E    0    0    0    0 2886
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9998, 1)
##     No Information Rate : 0.2843     
##     P-Value [Acc > NIR] : < 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
```

## 3.2 Model No.2
use function selection to reduce the 59 predictors to just 7 chosen variables: classe ~ roll_belt + pitch_belt + yaw_belt + magnet_arm_x + gyros_dumbbell_y + magnet_dumbbell_y + pitch_forearm.
This model achieves an accuracy of 98.16% with an expected error of 1.81%.
The expected error is greater, but it is still very successful considering that this model uses 52 fewer predictors.
To create this model, triple cross validation was implemented with the caret package.

```{r, eval=FALSE,echo=TRUE}
#Using Correlation based feature selection and best-first algorithm
features <- cfs(classe~.,train_raw[,-c(1:7)])
f <- as.simple.formula(features, "classe")

fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 3,
                           ## repeated ten times
                           repeats = 3)

model2 <- train(f, method = "rf", data =train_raw, trControl = fitControl)

model2
```
```{r, eval=FALSE,echo=TRUE}
## Random Forest 
## 
## 15699 samples
##     7 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 10466, 10465, 10467 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.9761127  0.9697912
##   4     0.9738197  0.9668918
##   7     0.9661761  0.9572249
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.
```
```{r, eval=FALSE,echo=TRUE}
pred_test2 <- predict(model2, test)
pred_train2 <- predict(model2, train)

confusionMatrix(pred_test2, test$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1098    8    0    2    0
##          B    7  732    3    0    5
##          C    4   15  679    5    1
##          D    6    4    2  636    4
##          E    1    0    0    0  711
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9829          
##                  95% CI : (0.9784, 0.9867)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2e-16         
##                                           
##                   Kappa : 0.9784          
##  Mcnemar's Test P-Value : 0.00075         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9839   0.9644   0.9927   0.9891   0.9861
## Specificity            0.9964   0.9953   0.9923   0.9951   0.9997
## Pos Pred Value         0.9910   0.9799   0.9645   0.9755   0.9986
## Neg Pred Value         0.9936   0.9915   0.9984   0.9979   0.9969
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2799   0.1866   0.1731   0.1621   0.1812
## Detection Prevalence   0.2824   0.1904   0.1795   0.1662   0.1815
## Balanced Accuracy      0.9902   0.9798   0.9925   0.9921   0.9929
```
```{r, eval=FALSE,echo=TRUE}
confusionMatrix(pred_train2, train$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 4464    0    0    0    0
##          B    0 3038    0    0    0
##          C    0    0 2738    0    0
##          D    0    0    0 2573    0
##          E    0    0    0    0 2886
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9998, 1)
##     No Information Rate : 0.2843     
##     P-Value [Acc > NIR] : < 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
```

## 3.3 Model No.3
adjusted using summary data provided. This model achieves an accuracy of only 71.74%, or an expected error rate of 28.26% against the test validation set. To create this model, triple cross validation was implemented with the caret package.

```{r, eval=FALSE,echo=TRUE}
#Predicting off of summary 
features3 <- cfs(classe~.,train_done[,-c(1:7)])
z <- as.simple.formula(features3, "classe")

model3 <- train(z, method = "rf", data =train_done, trControl = fitControl)

model3
```
```{r, eval=FALSE,echo=TRUE}
## Random Forest 
## 
## 187 samples
##  11 predictor
##   5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 124, 126, 124 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##      2  0.2567439  0.0000000
##     53  0.6462833  0.5482757
##   1456  0.6782028  0.5940114
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 1456.
```

```{r, eval=FALSE,echo=TRUE}
pred_test3 <- predict(model3, test_done)
pred_train3 <- predict(model3, train_done)

confusionMatrix(pred_test3, test_done$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction A B C D E
##          A 9 3 2 1 0
##          B 1 6 1 1 1
##          C 0 0 6 0 0
##          D 0 0 0 6 1
##          E 0 1 0 0 7
## 
## Overall Statistics
##                                           
##                Accuracy : 0.7391          
##                  95% CI : (0.5887, 0.8573)
##     No Information Rate : 0.2174          
##     P-Value [Acc > NIR] : 6.634e-14       
##                                           
##                   Kappa : 0.6722          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9000   0.6000   0.6667   0.7500   0.7778
## Specificity            0.8333   0.8889   1.0000   0.9737   0.9730
## Pos Pred Value         0.6000   0.6000   1.0000   0.8571   0.8750
## Neg Pred Value         0.9677   0.8889   0.9250   0.9487   0.9474
## Prevalence             0.2174   0.2174   0.1957   0.1739   0.1957
## Detection Rate         0.1957   0.1304   0.1304   0.1304   0.1522
## Detection Prevalence   0.3261   0.2174   0.1304   0.1522   0.1739
## Balanced Accuracy      0.8667   0.7444   0.8333   0.8618   0.8754
```

```{r, eval=FALSE,echo=TRUE}
confusionMatrix(pred_train3, train_done$classe)
```
```{r, eval=FALSE,echo=TRUE}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  A  B  C  D  E
##          A 48  0  0  0  0
##          B  0 39  0  0  0
##          C  0  0 31  0  0
##          D  0  0  0 34  0
##          E  0  0  0  0 35
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9805, 1)
##     No Information Rate : 0.2567     
##     P-Value [Acc > NIR] : < 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2567   0.2086   0.1658   0.1818   0.1872
## Detection Rate         0.2567   0.2086   0.1658   0.1818   0.1872
## Detection Prevalence   0.2567   0.2086   0.1658   0.1818   0.1872
## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
```

## 4. Conclusion
Predicting outside the summary statistics is much less accurate. The most differentiating variable is the tone of the strap sensor. This quickly distinguishes many cases in which the individual makes a Class E error.
The first model obtained the best overall performance and will be used to predict the validation set.

```{r, eval=FALSE,echo=TRUE}
predict(model1,validation)
```
```{r, eval=FALSE,echo=TRUE}
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
```
## 5. Appendix
```{r, eval=FALSE,echo=TRUE}
## 
## Call:
##  randomForest(formula = classe ~ ., data = train_raw[, -c(1:7)],      method = "class") 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.43%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4461    1    0    1    1 0.000672043
## B   13 3019    6    0    0 0.006254115
## C    0   11 2725    2    0 0.004747991
## D    0    0   27 2544    2 0.011270890
## E    0    0    1    3 2882 0.001386001
```
```{r, eval=FALSE,echo=TRUE}
## Random Forest 
## 
## 15699 samples
##     7 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 10466, 10465, 10467 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.9761127  0.9697912
##   4     0.9738197  0.9668918
##   7     0.9661761  0.9572249
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.
```

```{r, eval=FALSE,echo=TRUE}
## Random Forest 
## 
## 187 samples
##  11 predictor
##   5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 124, 126, 124 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##      2  0.2567439  0.0000000
##     53  0.6462833  0.5482757
##   1456  0.6782028  0.5940114
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 1456.
```
